#!/bin/bash

#SBATCH -J llm_train
#SBATCH --partition=gpu_h100
#SBATCH --gres=gpu:1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=4
#SBATCH --mem=32G
#SBATCH --time=24:00:00       # 24-hour wall clockâ€”adjust as needed
#SBATCH -o jobs/logs/train_%j.log

mkdir -p jobs/logs

# load CUDA and Conda (if needed)
# module load cuda
source "$HOME/miniconda3/etc/profile.d/conda.sh"

# activate the env you created
conda activate ./thesis_env

# run the training script
python src/train.py


